# -*- coding: utf-8 -*-
"""
Handler of the lambda function 'LambdaTrafficSensors'.
"""
# Import libraries
from io import StringIO
import uuid
import boto3
import pandas as pd
import botocore.config

cfg = botocore.config.Config(retries={'max_attempts': 0})
client = boto3.client('s3', config=cfg)

def batch_write(table_name, items, add_key=False):
    """
    write list of items dictionaries into a DynamoDB table

    Arguments:
    table_name -- name of the DynamoDB table to be filled
    items -- list of dictionaries (items)
    add_key -- if a primary key is added to the items
    """
    dynamodb = boto3.resource('dynamodb')
    db = dynamodb.Table(table_name)
    with db.batch_writer() as batch:
        for item in items:
            if add_key:
                item["elt_id"] = str(uuid.uuid4())
            batch.put_item(Item=item)

def handler(event, context):
    """
    Handler of the lambda function 'LambdaTrafficSensors':
    Loads the csv file of sensors data generated by 'LambdaTraffic'
    lambda function and dumps it in 'sensors_database' DynamoDB table.
    Once items are added, the csv file is deleted from "reconai-traffic" s3 bucket.
    """
    csvfile = client.get_object(Bucket='reconai-traffic', Key='sensors_data.csv')
    csvcontent = csvfile['Body'].read().decode('utf-8')
    df = pd.read_csv(StringIO(csvcontent))
    df = df.astype(str)
    sensors = df.to_dict('records')
    batch_write('sensors_database', sensors, add_key=True)
    client.delete_object(Bucket="reconai-traffic", Key='sensors_data.csv')
